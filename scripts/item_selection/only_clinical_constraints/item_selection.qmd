---
title: "FAI Item Selection"
format: pdf
editor: source
---


```{r}
suppressPackageStartupMessages({
  library("tidyverse")
  library("TAM")
  library("psych")
  library("lordif")
  library("ggridges")
  library("ggpubr")
  library("paletteer")
  library("readxl")
  library("mice")
  library("VIM")
  library("paran")
  library("lavaan")
  library("polycor") # for hetcor()
  library("multilevel")
  library("miceRanger")
  library("papaja")
  theme_set(theme_apa())
  library("outForest")
  library("lavaanExtra")
  # Caricare le librerie necessarie
  library(glmnet) # Per LASSO regression
  library(randomForest) # Per valutare importanza delle variabili
  library(Boruta) # Per selezione robusta delle variabili
  library(missRanger)
  library(caret)
  library(pROC)
  library(lavaan)
  library(semTools)
})

library("here")

# Increase max print
options(max.print = .Machine$integer.max)

source(here("functions", "fai_funs.R"))
```


## Import data

```{r}
fai_s <- read_xlsx(
  here("data", "raw", "FAI_TOT_2020_corrected.xlsx"), col_names = TRUE
)
```

Demographic information.

```{r}
#| output: false
demo_info <- recode_demo_info(fai_s)
```

Categorize disease severity.

```{r}
# Function to categorize disease severity
categorize_severity <- function(disease) {
  disease <- tolower(disease) # Normalize text (case insensitive)
  
  if (grepl("allergia|asma lieve|rinite", disease)) {
    return("Lieve")
  } else if (grepl("diabete|colite ulcerosa|artrite|cardiopatia|insufficienza renale|ipertensione", disease)) {
    return("Moderata")
  } else if (grepl("fibrosi cistica|leucemia|epilessia|distrofia|sindrome nefrosica|osteosarcoma|sarcoma|neuroblastoma", disease)) {
    return("Grave")
  } else if (grepl("tumore|cancro|metastasi|cuore ipoplasico|malattia metabolica|aciduria|encefalopatia", disease)) {
    return("Critica")
  } else {
    return(NA) # Unclassified
  }
}

# Apply the function to categorize chronic diseases
demo_info <- demo_info %>%
  mutate(severity_level = factor(
    sapply(chronic_disease, categorize_severity),
                                 levels = c("Moderata", "Lieve", "Grave", "Critica"),
                                 ordered = TRUE)
  )

# Verify transformation
# table(demo_info$severity_level, demo_info$death_risk)
```

In the original administration, there is no psychological criterion variable available. The only external variable that could serve as a criterion is death risk, based on the assumption that coping is more challenging for a life-threatening disease compared to a non-life-threatening condition.

```{r}
table(demo_info$death_risk)
```


## Data Wrangling

Extract item responses (columns 51 to 247).

```{r}
items <- fai_s[, 51:247]
colnames(items) <- paste0("item_", seq_len(ncol(items))) # Rename items
```

Identify and remove items with excessive missing values.

```{r}
n_nas <- colSums(is.na(items))
bad_items <- names(n_nas[n_nas > 50])  # Adjust threshold as needed
items_filtered <- items %>% 
  dplyr::select(-all_of(bad_items))
```

Combine cleaned item data with demographic info.

```{r}
mydata <- bind_cols(demo_info, items_filtered) %>%
  mutate(subj_id = as.factor(seq_len(nrow(.))))  
```

## Identify and Remove Problematic Participants

```{r}
d_num <- mydata %>%
  dplyr::select(starts_with("item_")) %>%
  dplyr::select(where(is.numeric))  # Ensure numeric selection

# Mahalanobis Distance
mahal_out <- careless::mahad(d_num)
mahal_cutoff <- boxplot(mahal_out, plot = FALSE)$stats[5]
bad_mahal <- mydata$subj_id[mahal_out > mahal_cutoff]

# Longstring Analysis
longstring_out <- careless::longstring(d_num)
longstring_cutoff <- boxplot(longstring_out, plot = FALSE)$stats[5]
bad_longstring <- mydata$subj_id[longstring_out > longstring_cutoff]

# IRV Analysis
irv_out <- careless::irv(d_num)
irv_cutoff <- boxplot(irv_out, plot = FALSE)$stats[5]
bad_irv <- mydata$subj_id[irv_out > irv_cutoff]

# Person Total Correlation
cm <- colMeans(d_num, na.rm = TRUE)
person_tot_cor <- apply(d_num, 1, function(x) cor(x, cm, use = "complete.obs"))
person_tot_cutoff <- boxplot(person_tot_cor, plot = FALSE)$stats[1]
bad_person_tot <- mydata$subj_id[person_tot_cor < person_tot_cutoff]

# Combine all flagged participants
bad_ids <- unique(c(bad_mahal, bad_longstring, bad_irv, bad_person_tot))

# Remove problematic participants before imputation
d_clean <- mydata %>%
  dplyr::filter(!subj_id %in% bad_ids)
```

## Multiple Imputation 

```{r}
#| output: false
#| cache: true
#| 
# Select numeric item responses for imputation
items_clean <- d_clean %>%
  dplyr::select(starts_with("item_")) %>%
  dplyr::select(where(is.numeric))

# Perform multiple imputation
imp <- missRanger(items_clean, num.trees = 100)

# Ensure imputed values are within the original range and rounded to integers
imp <- imp %>%
  mutate(across(everything(), ~ round(pmax(min(., na.rm = TRUE), 
                                           pmin(., max(., na.rm = TRUE))), 0)))

# Extract demographic data excluding items
demo_clean <- d_clean %>%
  dplyr::select(-starts_with("item_"))

# Final cleaned dataset
df <- bind_cols(imp, demo_clean)
```

```{r}
dim(df)
```

## Item Selection Based on Clinical Criteria

```{r}
# Define selected items based on clinical criteria
selected_items <- c(
  "i_86", "i_57", "i_5", "i_85", "i_81", 
  "i_105", "i_48", "i_133", "i_129", "i_39", "i_103", 
  "i_143", "i_79", 
  "i_111", "i_34", "i_119", "i_116", "i_23", "i_45", "i_41", 
  "i_186", "i_38", "i_128", "i_7", "i_16", "i_29", 
  "i_137", "i_96", "i_194"
)

# Convert to match column names in `imp`
selected_items_corrected <- paste0("item_", sub("^i_", "", selected_items))

# Ensure only existing columns are selected
selected_items_corrected <- intersect(selected_items_corrected, colnames(imp))

# Select the matching columns
imp_selected <- imp %>% 
  dplyr::select(any_of(selected_items_corrected))

# Validate the selection
if (length(selected_items_corrected) != length(selected_items)) {
  warning("Some selected items were not found in the dataset.")
}
print(names(imp_selected))
```

### Define Target Matrix for Factor Structure (29x6)

```{r}
# Initialize a 29x6 matrix filled with zeros
TARGET <- matrix(0, nrow = length(selected_items_corrected), ncol = 6)

# Assign factor loadings based on clinical criteria
TARGET[1:5, 1]  <- 1  # F1
TARGET[6:11, 2] <- 1  # F2
TARGET[12:13, 3] <- 1 # F3
TARGET[14:20, 4] <- 1 # F4
TARGET[21:26, 5] <- 1 # F5
TARGET[27:29, 6] <- 1 # F6

# Add row names for clarity
rownames(TARGET) <- selected_items_corrected
colnames(TARGET) <- paste0("F", 1:6)

# Print the target rotation matrix
print(TARGET)
```

### Define the ESEM Model in Lavaan Syntax

```{r}
model <- '
    efa("efa1")*f1 +
    efa("efa1")*f2 +
    efa("efa1")*f3 +
    efa("efa1")*f4 +
    efa("efa1")*f5 +
    efa("efa1")*f6 =~ 
       # F1
       item_86 + item_57 + item_5 + item_85 + item_81 + 
       # F2
       item_105 + item_48 + item_133 + item_129 + item_39 + item_103 + 
       # F3
       item_143 + item_79 + 
       # F4
       item_111 + item_34 + item_119 + item_116 + item_23 + item_45 + item_41 + 
       # F5
       item_186 + item_38 + item_128 + item_7 + item_16 + item_29 + 
       # F6
       item_137 + item_96 + item_194
'
```

### Fit the ESEM Model with Target Rotation

```{r}
fit1 <- sem(
  model = model,
  data = imp_selected,  
  ordered = TRUE,  # Use ordered estimation if Likert-type items
  rotation = "target",
  rotation.args = list(target = TARGET)
)
```

```{r}
fit_indices <- fitMeasures(fit1, c(
  "chisq", "df", "pvalue", "cfi", "tli", "rmsea", "srmr",
  "chisq.scaled", "df.scaled", "pvalue.scaled", "cfi.robust", "tli.robust",
  "rmsea.robust", "srmr"
))

# Display selected fit indices (Standard & Robust)
cat("\nModel Fit Indices (Standard & Robust):\n")
fit_indices_df <- data.frame(
  Measure = names(fit_indices),
  Value = round(fit_indices, 3)
)
print(fit_indices_df)
```

```{r}
# Extract Standardized Factor Loadings
# Get standardized solution
std_solution <- standardizedSolution(fit1)

# Filter only loadings (Lambda matrix)
std_loadings <- std_solution %>%
  filter(op == "=~") %>%
  dplyr::select(lhs, rhs, est.std) %>%
  arrange(lhs, desc(abs(est.std)))  # Sorted by factor and magnitude

colnames(std_loadings) <- c("Factor", "Item", "Standardized Loading")

# Display standardized loadings
cat("\nStandardized Factor Loadings:\n")
print(std_loadings)
```

```{r}
# Extract Interfactor Correlations

# Extract standardized correlations (Phi matrix)
interfactor_corr <- std_solution %>%
  dplyr::filter(op == "~~" & lhs != rhs) %>%  # Only factor correlations
  dplyr::select(lhs, rhs, est.std) %>%
  arrange(desc(abs(est.std)))  # Sort by magnitude

colnames(interfactor_corr) <- c("Factor 1", "Factor 2", "Standardized Correlation")

# Display interfactor correlations
cat("\nInterfactor Correlations:\n")
print(interfactor_corr)
```


### Classification Accuracy

```{r}
# Extract manifest variables (indicators) from the fitted model
indicator_names <- lavNames(fit1, type = "ov")

# Select corresponding variables from imputed data
XX <- imp_selected |> 
  dplyr::select(all_of(indicator_names))

# Convert to matrix for modeling
X <- as.matrix(XX)
y <- df$death_risk  

# Ensure death_risk is a binary factor
df$death_risk <- as.factor(df$death_risk)

# Merge imp_selected with the outcome variable
df_model <- imp_selected %>%
  mutate(death_risk = df$death_risk)

# Split data into training (80%) and testing (20%) sets
set.seed(123)  # For reproducibility
trainIndex <- createDataPartition(df_model$death_risk, p = 0.8, list = FALSE)
train_data <- df_model[trainIndex, ]
test_data <- df_model[-trainIndex, ]

# Fit logistic regression model
logit_model <- glm(death_risk ~ ., data = train_data, family = binomial)

# Predict probabilities on test set
pred_probs <- predict(logit_model, test_data, type = "response")

# Convert probabilities to class labels (0.5 threshold)
pred_classes <- factor(ifelse(pred_probs > 0.5, 1, 0), levels = levels(test_data$death_risk))

# Compute classification accuracy
accuracy <- mean(pred_classes == test_data$death_risk)
cat("Classification Accuracy:", round(accuracy, 3), "\n")

# Compute AUC (Area Under the Curve)
roc_curve <- roc(test_data$death_risk, pred_probs)
auc_value <- auc(roc_curve)
cat("AUC:", round(auc_value, 3), "\n")
```

```{r}
# Permutation Test: Evaluating Accuracy Against Chance Level

set.seed(123)
null_accuracies <- replicate(1000, {
  shuffled_risk <- sample(train_data$death_risk)  # Shuffle class labels
  
  # Fit model on shuffled labels
  null_model <- glm(shuffled_risk ~ ., data = train_data, family = binomial)
  
  # Predict using null model
  null_preds <- predict(null_model, test_data, type = "response")
  null_classes <- factor(ifelse(null_preds > 0.5, 1, 0), levels = levels(test_data$death_risk))
  
  mean(null_classes == test_data$death_risk)  # Compute accuracy on actual test labels
})

# Compute p-value: Proportion of null models performing as well as or better than the real model
p_value <- mean(null_accuracies >= accuracy)
cat("P-value for classification above chance:", round(p_value, 4), "\n")
```


```{r}
# Plot ROC Curve
plot(roc_curve, col = "blue", main = "ROC Curve")
abline(a = 0, b = 1, lty = 2, col = "red")  # Reference line for random classification
```

## Remove the worse items

```{r}
selected_items <- c(
  "i_86", "i_57", "i_5", "i_81", 
  "i_105", "i_48", "i_133", "i_129", "i_39", "i_103", 
  "i_143", "i_79", 
  "i_111", "i_34", "i_119", "i_116", "i_23", "i_41", 
  "i_186", "i_38", "i_128", "i_7", "i_16", 
  "i_137", "i_96", "i_194"
)

# Convert to match column names in `imp`
selected_items_corrected <- paste0("item_", sub("^i_", "", selected_items))

# Ensure only existing columns are selected
existing_items <- intersect(selected_items_corrected, colnames(imp))

# Issue a warning if any items are missing
missing_items <- setdiff(selected_items_corrected, existing_items)
if (length(missing_items) > 0) {
  warning("The following items were not found in the dataset: ", paste(missing_items, collapse = ", "))
}

# Select the matching columns
imp_selected <- imp %>% 
  dplyr::select(all_of(existing_items))

# Validate the selection
print(names(imp_selected))
```

```{r}
# Define Target Matrix for Factor Structure (26x6)

# Initialize a 26x6 matrix filled with zeros
TARGET <- matrix(0, nrow = length(existing_items), ncol = 6)

# Assign factor loadings dynamically
factor_assignments <- list(
  F1 = c(1:4),
  F2 = c(5:10),
  F3 = c(11:12),
  F4 = c(13:18),
  F5 = c(19:23),
  F6 = c(24:26)
)

# Assign 1s based on factor structure
for (factor in names(factor_assignments)) {
  TARGET[factor_assignments[[factor]], as.numeric(substr(factor, 2, 2))] <- 1
}

# Add row and column names for clarity
rownames(TARGET) <- existing_items
colnames(TARGET) <- paste0("F", 1:6)

# Print the target rotation matrix
print(TARGET)
```

```{r}
# Define the ESEM Model in Lavaan Syntax

model <- '
    efa("efa1")*f1 + 
    efa("efa1")*f2 + 
    efa("efa1")*f3 + 
    efa("efa1")*f4 + 
    efa("efa1")*f5 + 
    efa("efa1")*f6 =~ 
       # F1
       item_86 + item_57 + item_5 + item_81 + 
       # F2
       item_105 + item_48 + item_133 + item_129 + item_39 + item_103 + 
       # F3
       item_143 + item_79 + 
       # F4
       item_111 + item_34 + item_119 + item_116 + item_23 + item_41 + 
       # F5
       item_186 + item_38 + item_128 + item_7 + item_16 +
       # F6
       item_137 + item_96 + item_194
'

# Fit the ESEM Model with Target Rotation
fit2 <- sem(
  model = model,
  data = imp_selected,  
  ordered = TRUE,  # Use ordered estimation if Likert-type items
  rotation = "target",
  rotation.args = list(target = TARGET)
)
```

```{r}
fit2_indices <- fitMeasures(fit2, c(
  "chisq", "df", "pvalue", "cfi", "tli", "rmsea", "srmr",
  "chisq.scaled", "df.scaled", "pvalue.scaled", "cfi.robust", "tli.robust",
  "rmsea.robust", "srmr"
))

# Display selected fit indices (Standard & Robust)
cat("\nModel Fit Indices (Standard & Robust):\n")
fit2_indices_df <- data.frame(
  Measure = names(fit2_indices),
  Value = round(fit2_indices, 3)
)
print(fit2_indices_df)
```

```{r}
# Extract Standardized Factor Loadings
# Get standardized solution
std_solution <- standardizedSolution(fit2)

# Filter only loadings (Lambda matrix)
std_loadings <- std_solution %>%
  filter(op == "=~") %>%
  dplyr::select(lhs, rhs, est.std) %>%
  arrange(lhs, desc(abs(est.std)))  # Sorted by factor and magnitude

colnames(std_loadings) <- c("Factor", "Item", "Standardized Loading")

# Display standardized loadings
cat("\nStandardized Factor Loadings:\n")
print(std_loadings)
```

```{r}
# Extract Interfactor Correlations

# Extract standardized correlations (Phi matrix)
interfactor_corr <- std_solution %>%
  dplyr::filter(op == "~~" & lhs != rhs) %>%  # Only factor correlations
  dplyr::select(lhs, rhs, est.std) %>%
  arrange(desc(abs(est.std)))  # Sort by magnitude

colnames(interfactor_corr) <- c("Factor 1", "Factor 2", "Standardized Correlation")

# Display interfactor correlations
cat("\nInterfactor Correlations:\n")
print(interfactor_corr)
```

## Combine the first two factors

Also, add additional items to maximize classification accuracy. These are the items that maximally contribute to accurate classification: item_22  item_23  item_26  item_40  item_99 item_121 item_125 item_139 item_157 item_159 item_164 item_187.

```{r}
selected_items <- c(
  "i_86", "i_57", "i_5", "i_81", 
  "i_105", "i_48", "i_133", "i_129", "i_39", "i_103", 
  "i_143", "i_79", 
  "i_111", "i_34", "i_119", "i_23", "i_41", "i_139",
  "i_186", "i_38", "i_128", "i_7", "i_16", "i_125", 
  "i_137", "i_96", "i_194", "i_159"
)

# Convert to match column names in `imp`
selected_items_corrected <- paste0("item_", sub("^i_", "", selected_items))

# Ensure only existing columns are selected
existing_items <- intersect(selected_items_corrected, colnames(imp))

# Issue a warning if any items are missing
missing_items <- setdiff(selected_items_corrected, existing_items)
if (length(missing_items) > 0) {
  warning("The following items were not found in the dataset: ", paste(missing_items, collapse = ", "))
}

# Select the matching columns
imp_selected <- imp %>% 
  dplyr::select(all_of(existing_items))

# Validate the selection
print(names(imp_selected))
```

```{r}
# Define Target Matrix for Factor Structure

# Determine the number of rows dynamically
num_items <- length(existing_items)
TARGET <- matrix(0, nrow = num_items, ncol = 5)

# Assign factor loadings dynamically
factor_assignments <- list(
  F1 = 1:10,    # Caratteristiche bambino e richieste caregiving
  F2 = 11:12,   # Percezione cura
  F3 = 13:18,   # Fattori intrapsichici
  F4 = 19:24,   # Coping
  F5 = 25:28    # Iperprotezione
)

# Assign 1s based on factor structure
for (factor in names(factor_assignments)) {
  TARGET[factor_assignments[[factor]], as.numeric(substr(factor, 2, 2))] <- 1
}

# Add row and column names for clarity
rownames(TARGET) <- existing_items
colnames(TARGET) <- paste0("F", 1:5)

# Print the target rotation matrix
print(TARGET)
```

```{r}
# Define the ESEM Model in Lavaan Syntax
model <- '
    efa("efa1")*f1 + 
    efa("efa1")*f2 + 
    efa("efa1")*f3 + 
    efa("efa1")*f4 + 
    efa("efa1")*f5 =~ 
       # F1
       item_86 + item_57 + item_5 + item_81 + 
       item_105 + item_48 + item_133 + item_129 + item_39 + item_103 + 
       # F2
       item_143 + item_79 + 
       # F3
       item_111 + item_34 + item_119 + item_23 + item_41 + item_139 +
       # F4
       item_186 + item_38 + item_128 + item_7 + item_16 + item_125 +
       # F4
       item_137 + item_96 + item_194 + item_159
'

# Fit the ESEM Model with Target Rotation
fit3 <- sem(
  model = model,
  data = imp_selected,  
  ordered = TRUE,  # Use ordered estimation if Likert-type items
  rotation = "target",
  rotation.args = list(target = TARGET)
)
```


```{r}
fit3_indices <- fitMeasures(fit3, c(
  "chisq", "df", "pvalue", "cfi", "tli", "rmsea", "srmr",
  "chisq.scaled", "df.scaled", "pvalue.scaled", "cfi.robust", "tli.robust",
  "rmsea.robust", "srmr"
))

# Display selected fit indices (Standard & Robust)
cat("\nModel Fit Indices (Standard & Robust):\n")
fit3_indices_df <- data.frame(
  Measure = names(fit3_indices),
  Value = round(fit3_indices, 3)
)
print(fit3_indices_df)
```

```{r}
# Extract Standardized Factor Loadings
# Get standardized solution
std_solution <- standardizedSolution(fit3)

# Filter only loadings (Lambda matrix)
std_loadings <- std_solution %>%
  filter(op == "=~") %>%
  dplyr::select(lhs, rhs, est.std) %>%
  arrange(lhs, desc(abs(est.std)))  # Sorted by factor and magnitude

colnames(std_loadings) <- c("Factor", "Item", "Standardized Loading")

# Display standardized loadings
cat("\nStandardized Factor Loadings:\n")
print(std_loadings)
```

```{r}
# Extract Interfactor Correlations

# Extract standardized correlations (Phi matrix)
interfactor_corr <- std_solution %>%
  dplyr::filter(op == "~~" & lhs != rhs) %>%  # Only factor correlations
  dplyr::select(lhs, rhs, est.std) %>%
  arrange(desc(abs(est.std)))  # Sort by magnitude

colnames(interfactor_corr) <- c("Factor 1", "Factor 2", "Standardized Correlation")

# Display interfactor correlations
cat("\nInterfactor Correlations:\n")
print(interfactor_corr)
```

### Classification Accuracy

```{r}
# Get observed variable names from the fitted model
indicator_names <- lavNames(fit3, type = "ov")

# Select corresponding variables from imputed dataset
XX <- imp_selected |> 
  dplyr::select(all_of(indicator_names))

# Convert to matrix for modeling
X <- as.matrix(XX)
y <- df$death_risk  # Outcome variable

# Ensure death_risk is a binary factor
df$death_risk <- factor(df$death_risk)

# Merge imputed data with the criterion variable
df_model <- imp_selected %>%
  mutate(death_risk = df$death_risk)

# Validate the factor levels
if (length(levels(df_model$death_risk)) != 2) {
  stop("Error: The death_risk variable must be binary.")
}

# Train-Test Split
set.seed(123)  # For reproducibility
trainIndex <- createDataPartition(df_model$death_risk, p = 0.8, list = FALSE)
train_data <- df_model[trainIndex, ]
test_data <- df_model[-trainIndex, ]
```

```{r}
# Fit Logistic Regression Model
logit_model <- glm(death_risk ~ ., data = train_data, family = binomial)

# Predict probabilities on test set
pred_probs <- predict(logit_model, test_data, type = "response")

# Convert probabilities to class labels using dynamic factor levels
threshold <- 0.5
pred_classes <- factor(ifelse(pred_probs > threshold, levels(df$death_risk)[2], levels(df$death_risk)[1]), 
                       levels = levels(df$death_risk))

# Compute classification accuracy
accuracy <- mean(pred_classes == test_data$death_risk, na.rm = TRUE)
cat("Classification Accuracy:", round(accuracy, 3), "\n")
```

```{r}
# Compute AUC (Area Under the Curve)
roc_curve <- roc(test_data$death_risk, pred_probs)
auc_value <- auc(roc_curve)
cat("AUC:", round(auc_value, 3), "\n")
```




```{r}
# Permutation Test: Evaluating Accuracy Against Chance Level
set.seed(123)
null_accuracies <- replicate(1000, {
  shuffled_risk <- sample(train_data$death_risk)  # Shuffle class labels
  
  # Fit model on shuffled labels
  null_model <- glm(shuffled_risk ~ ., data = train_data, family = binomial)
  
  # Predict using null model
  null_preds <- predict(null_model, test_data, type = "response")
  null_classes <- factor(ifelse(null_preds > threshold, levels(df$death_risk)[2], levels(df$death_risk)[1]), 
                         levels = levels(df$death_risk))
  
  mean(null_classes == test_data$death_risk, na.rm = TRUE)  # Compute accuracy on actual test labels
})

# Compute p-value: Proportion of null models performing as well as or better than the real model
p_value <- mean(null_accuracies >= accuracy)
cat("P-value for classification above chance:", round(p_value, 4), "\n")
```

```{r}
# Plot ROC Curve
plot(roc_curve, col = "blue", main = "ROC Curve")
abline(a = 0, b = 1, lty = 2, col = "red")  # Reference line for random classification
```

### Interpreting the Results

**Classification Accuracy:**

Measures the percentage of correct classifications in the test set.
If accuracy > 0.70, the model has reasonably good predictive power.

**AUC (Area Under the Curve):**

AUC = 0.5: Model performs at chance level (random guessing).
AUC > 0.7: Good discrimination between positive/negative cases.
AUC ≈ 1: Excellent classification performance.

**Permutation Test (p-value):**

Tests whether the classifier performs significantly better than chance.
If p < 0.05: The model significantly outperforms random classification.
If p ≈ 0.5: The model is not better than random guessing.

